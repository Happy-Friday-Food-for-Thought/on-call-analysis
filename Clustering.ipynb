{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Incident clustering\n",
    "\n",
    "This notebook clusters incidents together using a very naive Kmeans on top of TD-IDF vectorization.\n",
    "It is simple, but works well to group related notifications and pin-point the top-offenders in your alerting system \n",
    "\n",
    "Tune `KMEANS_CLUSTERS` below to get less or more clusters. \n",
    "\n",
    "As a prerequisite, you will need to run `poetry run oncall-analysis pagerduty incidents-log --start-date 2023-01-01` to get the data for analysis\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "from lets_plot import *\n",
    "LetsPlot.setup_html()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get the data from Pagerduty"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/incident_log.csv\")\n",
    "df = df.assign(week=df.created_at.dt.strftime('%Y-%m-%d')).sort_values('week')\n",
    "df.sort_values('week')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Use Kmeans to clusterize incidents together\n",
    "\n",
    "- https://jakevdp.github.io/PythonDataScienceHandbook/05.11-k-means.html\n",
    "- KMEANS_CLUSTERS = 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "KMEANS_CLUSTERS = 10\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# \n",
    "# TF-IDF vectorization\n",
    "#\n",
    "\n",
    "import re\n",
    "def preprocess(title):\n",
    "    return re.sub(r'[0-9]+', '', title)\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tf_idf_vect = TfidfVectorizer(lowercase=True,\n",
    "                              stop_words='english',\n",
    "                              ngram_range = (1,1),\n",
    "                              tokenizer = tokenizer.tokenize)\n",
    "vectorized = tf_idf_vect.fit_transform(df.title.map(preprocess))\n",
    "\n",
    "kmeans = KMeans(n_clusters=KMEANS_CLUSTERS)\n",
    "kmeans.fit(vectorized)\n",
    "\n",
    "labels = kmeans.labels_\n",
    "\n",
    "clustered = df.assign(cluster=labels)\n",
    "\n",
    "counts = clustered.groupby('cluster', as_index=True).aggregate('count')\n",
    "\n",
    "clustered"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get some common terms for clustered data and group counts for each cluster"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## print feature\n",
    "order_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = tf_idf_vect.get_feature_names_out()\n",
    "\n",
    "def getterms(cluster_index):\n",
    "    return \" \".join([terms[ind] for ind in order_centroids[cluster_index, :KMEANS_CLUSTERS]])\n",
    "\n",
    "common_terms = [getterms(i) for i in range(KMEANS_CLUSTERS)]\n",
    "termsdf = pd.DataFrame({'cluster': range(KMEANS_CLUSTERS), 'terms': common_terms})\n",
    "joined = termsdf.join(counts).sort_values('id', ascending=False)\n",
    "\n",
    "pd.options.display.max_colwidth = 500\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "joined"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clustered[clustered.cluster == 2]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Write clustesrs to data/clustered.xlsx to enjoy Excel's filtering and pivoting capabilities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Write the clustered incidents to data/clustered.xlsx file and enjoy reviews with your team \n",
    "(\n",
    "    clustered[['title', 'description', 'created_at', 'cluster']]\n",
    "        .assign(created_at=df.created_at.dt.strftime('%Y-%m-%d %H:%m:%S'))\n",
    "        .to_excel('data/clustered.xlsx')\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
